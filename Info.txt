Command Prompt > Tutorials Folder > 
git clone https://github.com/ThaWeatherman/scrapers.git

After Cloning, go to the cloned folder > find games.csv file 
put games.csv file and Board Game Review Prediction.ipynb files on the same level

or open a jupyter notebook on the same file level of games.csv




generating board game review predictions by using machine learning. This is going to be an awesome project where we import a dataset of over 80,000 games, and then use that information to train both a Linear Regression model and a Random Forest regressor to make predictions based off board game informations. This is going to be the final product of this project. So, we have 80,000 games with information like this minplayers, maxplayers, playingtime, etc. And then we use a Linear Regression model, which is linear, and then a nonlinear Random Forest regressor, both to make predictions that end up being pretty good. So, for this particular game, that was published in 2012, and has had over 19,000 users rate, we're able to fairly accurately predict the actual average review based off only the information shown above. So our Random Forest regressor is slightly better than the Linear Regression Prediction model, but that's to be expected with a dataset such as this, and a linear versus nonlinear regressor. So I hope you tune in, I will be walking you through all of the steps needed to generate this output, how you train the models, how you load and preprocess the dataset appropriately. So I hope that you will learn a lot, and I look forward to showing you how it works. Thank you very much.

Hello, everybody, and welcome to this tutorial video, where we're going to be building a board game review predictor using a couple of different regression models. We're going to use a Linear regressor, and we're also going to use a Random Forest regressor, and compare and contrast the results that we achieve in both of them. So this is going to be an excellent project, we're going to use a GitHub repository. So I'll show you how to install and use GitHub as well. And then once again, just like in our other project videos, we're going to be using a Jupyter Notebook to actually develop our application, as well as conda to install and manage our packages. So let's go ahead and dive right in. So, for this project, we're going to need data, as all machine learning projects do. And that data today is going to come from an individual on GitHub, who built a scraper that pulled a bunch of board game reviews and board game informations from boardgamegeek, I believe, was the website. So this is open source data, and it's available on GitHub. So I'm going to show you how to get there. And this is GitHub here. And actually, the repository that we are going to be using was developed by Sean Beck. And so, he's got a lot of different stuff on here. Once again, all open sourced, the boardgamegeek is where we're going to want to go, and he has this games.csv, which has all the information we need. It has, I think, around 81,000 different board games that are in this file and have information for and reviews. So it is an incredible source of information that will be available to us. And so it's usually important to check licensing. This is GitHub. So if it's, it's most of its open source. But, here we see again, that this has an MIT License, which means that we can use it and modify it in any way that we would want without liability or warranty. So, this is freely available to us, no worries about that there. So let's show you how you get this going. I'm going to start up my Anaconda. So I'm going to go to the Command Prompt, I'm actually going to run this as an administrator, just so I can modify some of my conda information. So cd, I'm going to go over to my tutorial folder. So there's that. Alright. And so now, there's a couple different ways to get information from GitHub. If you go back here, you can, GitHub is divided into repositories, you could download or clone this entire repository straight from online using this button here, and it provides the link. And you can download a zip file, just like that. However, GitHub comes up a lot. And oftentimes, you need to pull information from different repositories from the command line. So I'm actually going to show you how to install Git. I'm on Windows. So that's what I will be using. But there are installation instructions here for both Linux, Mac, and, of course, Windows, or you could install from source. So these are all good methods. I'll be doing the Windows method, and we'll show you how to get that set up. This installation is going to allow us to download these repositories straight from the command line. So let's do that. If you followed along with the other projects, like I'm sure you did, then you have conda already installed. Remember, Anaconda is a package manager. And so you can install Git straight from conda, and actually that's what I'm going to be doing. They do suggest using a Windows Installer here. However, since we've been using conda, we're going to go ahead and do that. So conda install [No audio] -c anaconda git, and this is going to do the installation. I already have this installed, so I'm not going to go ahead and click enter. But if you need to get Git, this would be a good time to pause the video, run enter, or run this command here, and make sure everything's set up and installed correctly. Alright, once we have that we can go ahead and clone the repository. So cloning repositories, once you have Git installed, is very, very easy. All you type is git clone, and clone is the same as like a download. It's a copy and download. And then we're going to type in our URL here actually, we can go straight here, and we can just Ctrl A and Ctrl C to copy this if we want. [No audio] So here is the URL, and this is the scrapers repository from Sean Beck, username ThaWeatherman. So once we have this, and whatever folder you are currently in is where it's going to download it. So we'll go ahead and click enter. So it's cloning, and here we go. And it got all those. So let's go ahead and open up our Windows Explorer. And we'll see if this did indeed [No audio] download. [No audio] So yes, we have the folder here, we actually don't need this entire repository. So what I'm going to go do now, and you see that all the files listed up on the GitHub page are here. What I'm going to do now is I'm going to go into that boardgamegeek folder, and I'm going to get that games.csv file, I'm going to copy it, I'm going to come all the way back out to my Tutorial folder and just paste this here. That's all we actually need. So I can go ahead and just delete this now, and we'll get rid of that. Alright, so we have our dataset. And now let's dive into opening it up and using it in Jupyter Notebooks with Python. So we'll go back to our command line here. And we'll just type jupyter notebooks, and Jupyter's in your path, this will open up our Jupyter Notebook, excuse me, this will open up a notebook in your web browser. So this can sometimes take a second or 2. But here we go. And it's starting that up. Alright, and so whatever folder that you were in when you type Jupyter Notebook, once again, is where it opens up your project. So you can see we have our games.csv file right here. Since we're in the Tutorial folder. That's perfect. That's what we need. I'm going to start a New notebook here, just do Python(default). [No audio] And let's give this a name. We'll call it Board Game Review Prediction. Perfect. Now we will know what it is. Alright. So, we're going to have to import a couple packages. And remember, if one of these throws an error, it's as simple as going back and typing conda install whatever package you needed. But for now let's just import them and make sure that we're all on the same page. I'm going to do an import sys, so we can see which version of Python I'm using, import pandas, import matplotlib, import seaborn, is a new one that we're going to need, and then import sklearn. So I want to do print functions here, so we can see which versions we are using. [No audio] Oh, no capital needed. [No audio] So we'll do this for all of them. [No audio] It's important that we're using the same versions, sometimes because you'll get different results. So it's always a good idea to check. I'm using Python 2.7, that's going to be the most important one. [No audio] But all these others are good to check as well. Alright, so Shift Enter to run this cell. And it's thinking, trying to import all of these, I should have all of them installed already. You may need to go back and install seaborn, these other ones we should have used in previous projects. So those should already be available and accessible. [No audio] It is thinking, thinking, [No audio] and there we go. So Python 2.7. This is the pandas, matplotlib, seaborn, and sklearn. Alright, but we actually need to go back and import some specific packages. So let's do import matplotlib.pyplot as plt, and we're going to import seaborn as sns, and then we're actually going to import the models, well, the sklearn models that we need. We might actually, well we can do the train test split from this one. We'll wait on doing the Random Forest and the Linear regressor until later. So we're going to need the model_selection import train_test_split. Alright, and we're going to go ahead and click Shift Enter on this once again.

So there we go, we see the two, it's successfully run, no errors. Alright. And now let's work on loading in our dataset using Pandas. So it's really easy. We're going to call this our dataset games, this is going to be a pandas dataframe, and it's going to just do pandas.read.csv, very appropriately named, and then just the name of the file here. [No audio] And we should be good to go there. So let me add some comments for readability. Comments are always good, [No audio] load the data. Alright. And let's actually just click Shift Enter there, we'll see if we can get that, we should. Yes, it does it very quickly. Alright. So now let's explore this dataset a little bit to see what we have in this games.csv in this file, so let's Print the names of the columns in games. And so to do that, we'll just do print(games.columns). And actually, let's do a print(games.shape) as well, so we know how much is there. [No audio] Alright, here we go. So we have, oh, wow, we have 81,000 games, 312, 20 different columns, we have id, the type, name, yearpublished, minplayers, maxplayers, playingtime, etc., etc. So the one that we're really interested in is the average_rating here. This is what we're going to be trying to predict based off some of these other characteristics of the game. Like average_weight. Here, weight is a function of the complexity of the game. So the higher the weight, the more complex the game is, this one's actually going to be important for our final predictions. Alright, so let's explore this a little bit, let's make a histogram of all the ratings in the average_rating column, [No audio] average_rating. Alright, to do that, we'll use plt. And we can just use the plt.hist, this will generate a histogram. And so we want games. But we don't want all the columns, we only want the average_rating here, so just the average_rating column. And then after that, we need to show the plot. So plt, you need to do a, or the pipeline, you need plt.show, Shift Enter. Alright, here we go. And this is kind of unexpected. So we see here, we have almost 24,000, 25,000 games with an average_rating of 0. So that's not really promising. But let's explore what this means a little bit, a little bit more, because right now we have a lot of 0 and then we have a skew to the right where we have an average prediction of 6, just about. So let's do a print first row of all the games with 0 scores. [No audio] So we can see what's going on with these guys. And so we're going to use the .iloc method, which for dataframes allows us to index by position. So we'll do a print(games, and we'll have the [games["average_rating"] again, where this is equal to 0, those are the ones we're interested in, and we want to do .iloc, this is indexing by position, we'll just take the first one of those. [No audio] Alright. And to compare and contrast this, let's do a Print the first row of games with scores greater than 0 as well. So we can see what's going on with those and if there's differences. So I'm going to just go up here, I'm going to highlight this, Ctrl C to copy and then Ctrl V to paste. I'm going to change this right here. We don't want equals to, we want greater than. Alright, so, let's explore this, Shift Enter. So here's our first one where review equals 0. So we have an id, type, name, and then just no information. So we have one wisher. I'm not entirely sure what that means. Maybe somebody wants this game, but it looks like it was never published. 0 users rated, average_rating 0. So, this game doesn't exist. And that's why we're getting this information. However, this one, Twilight Struggle, published in 2005, and has all this other information. So average_rating 8.3, pretty good, because 20,000 people actually rated it. So we want games where people have actually reviewed these, so that we don't have all of these 0s in our data. And once again, when we're doing machine learning, this is why it's so important to explore the data before starting. Because sometimes you have information like this, that is going to really impact your results in a negative way. So let's take care of that right, now. What we're going to do is we're going to Remove any rows without user reviews. So this is going to be pretty easy. So we want our dataframe games again. And we'll just do games[games where the "users_rated", [No audio] is going to be greater than 0. So as long as somebody's reviewed this game, somebody's played it and reviewed it, we're going to assume it's okay. [No audio] And then we want to Remove any rows with missing values as well, because that is also going to impact our results. [No audio] And this actually is going to be dropping the first axis, so we'll just do axis=0 here. Alright. And now let's make another histogram. [No audio] And we'll do the average_ratings again. So once again, this is plt.hist. So (games["average_rating"]. Awesome. And we need the plt.show as well. Shift Enter, we'll see if this comes up. And it does. Here we go. Let's see that, ah, looks much better now. We don't have that 0, and everything looks more appropriate than before. You see we actually lost some here, we had some missing data. So, this shape as well changed slightly. [No audio] Alright, so let's move on. What we want to do is actually, well, first, this, I believe was dropping the id column, let me do a game, we'll do a print(games.columns), and we'll run this again. Okay, so, we have all the same information in there. We might want to go back and drop this 'id' column, but we'll see how it impacts our final results. The 'id' column doesn't really tell you any useful information about the game, since it is signed arbitrarily, however, you might get some biases and it might result in actually overfitting if you include id's in your machine learning training data. But for now, let's develop a correlation matrix. So what this is going to do is going to tell us if there are some strong correlations between some of these parameters in our dataset. So we're going to use seaborn for this. And this is a really cool way to do a correlation matrix. We've done it slightly different in the past. But this is a new way. So we'll see how this works right here. So we want a corrmat. And we're going to develop this with simply the games.corr, which is part of the pandas DataFrame. So this right here is the pandas DataFrame, and this is one of the functions that they provide. So we need to figure, so we'll do a plt.figure, and we're going to, I'm going to assign a fisize to this, simply so it looks nice. [No audio] So that's that. And then here we have our seaborn, and we're going to have the sns, and we're going to develop a heatmap, and that's going to be based off our corrmat, our correlation matrix, and we have some parameters here just to make it look nicer, [No audio] square = True. So there's those. Alright, and let's try this one more time with a plt.show. See if this works. Alright, Shift Enter. [No audio] So this will take a little sec, okay. We have an error. Let's see what our error is. We spelled a word wrong. Alright. There we go. [No audio] And here it is. So this is really awesome. And it's a heatmap. So showing the correlations between our different parameters here, with 0.8 being the highest, and that being a white, and all the way down here in the black and about the 0, that is no correlation. So I see some pretty obvious correlations right now. No surprise, playingtime is highly correlated with minplaytime and maxplaytime. So that doesn't really tell us much useful information. But down here, we see some other things as well. The total_weights is fairly highly, or the average_weight. And remember, our average_rating is the one that's important. So you see the id is highly correlated with average_rating. And then as well, the average_weight is fairly highly correlated. So some of these, like the minage is correlated with the rating as well, as well as the bayes_average_rating, we're probably going to want to remove that because it's based off the average_rating. [No audio] So, we're going to remove some of these, because they don't actually tell us useful information. We don't want to have the type or the name or the id, because this is all stuff that isn't actually characteristics of the game, but since they are highly correlated, are going to impact our results of our machine learning algorithm. Alright, so let us do that now. So what we're going to do, this is part of the dataset preprocessing, very important to machine learning. We're going to Get all the columns from the DataFrame. And to do that, we need columns = games.columns.tolist is a very convenient function to generate a list, a Python list. And then what we want to do is we're going to Filter the columns to remove data we do not want. So this is a very important step here. And so we'll have columns =, and we're going to do a for loop in here. So c for c in columns if c not in, and then here are the ones we're going to be excluding. So we don't want the "bayes_average_rating", because that's based off the average_rating. So it doesn't really tell us useful information. We're also going to want to remove the "average_rating", because we don't want to be trying to predict data that's in our training set, and we're going to remove the "type", and we're going to remove the "name". And then lastly, we're going to remove the "id". [No audio] So those are all data that we don't want. [No audio] But we also want to Store the variable we'll be predicting on. [No audio] So to do that, we say target, and target being our target variable is going to be "average_rating". Alright, so let us just run a Shift Enter on this. So this will filter out the bayes_average_rating, the average_rating, type, name, and id. And now we're going to split the datasets and Generate [No audio] training and test datasets. [No audio] So, to do that, we already imported this, but it's from the sklearn., here we go, learn.cross_validation. So you don't need to type this again. Just for readability, though, it'll be nice to have this down here, so we know where our functions are coming from. So, we are also going to write here, we're going to Generate the training set, [No audio] and we're also going to set a random seed so that we can replicate these results. So we'll do train = games.sample. So fraction, we want about 80% of the data, so that's 0.8, 20% of the data for a testing dataset is usually pretty standard, you want about 20%. [No audio] So random_state, we're just going to set to 1, not so random. But this will allow us to reproduce our data, and allow you guys to get the same results that I'm getting. Alright. So we want to Select anything not in the training set, [No audio] and we're going to put it in the test set. So do that we want test = games, and so we'll have .loc. So this is going to be label-based indexing. And we're going to do the games.index.isin(train.index). [No audio] And instead of a parenthesis here, I need a, no, no, that's right, train isin. Yes, there we go. So, let me also Print the shapes of both of these. So we'll do a train.shape. So we can see if our data was divided appropriately. So we'll do a test.shape as well. So Shift Enter here, [No audio] and here we go. So this actually got removed in favor of model selection. So let's see if I can remove this and it will be, [No audio] there we go. Now it is not yelling at me. So I have 45,000 games in our training data, and 11,000 in the testing data, so pretty big datasets here. And that is what we want to see. Alright, so I'm going to actually stop this video here. This is just setting up the dataset. In the next one, it will be a little bit shorter. We are going to dive into using our Linear Regression model as well as our Random Forest model, and compare and contrast the results. So good job getting the dataset imported from GitHub, and preprocessed in a way that we can now use it for machine learning. So talk to you soon. Thanks.

